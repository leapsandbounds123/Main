{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer month into season\n",
    "def month_season(sample):\n",
    "    # input: df, output: df\n",
    "    Season = np.zeros([sample.shape[0]])\n",
    "    Season[(sample['month'] <= 5) & (sample['month'] >= 3)] = 1\n",
    "    Season[(sample['month'] <= 8) & (sample['month'] >= 6)] = 2\n",
    "    Season[(sample['month'] <= 11) & (sample['month'] >= 9)] = 3\n",
    "    Season[sample['month'] <= 2] = 4\n",
    "    Season[sample['month'] == 12] = 4\n",
    "    sample['Season'] = Season\n",
    "    return (sample)\n",
    "\n",
    "# using one hot coding to transfer categorical variables as binary variables\n",
    "def onehotcode(sample):\n",
    "    # input: df, output: df\n",
    "    binary_season = pd.get_dummies(sample['Season'])\n",
    "    binary_season.columns = (['spring', 'summer', 'fall', 'winter'])\n",
    "    binary_year = pd.get_dummies(sample['year'])\n",
    "    binary_dayofweek = pd.get_dummies(sample['dayofweek'])\n",
    "    binary_dayofweek.columns = (['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "    frames = [binary_season, binary_year, binary_dayofweek]\n",
    "    final = pd.concat(frames, axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    return final  # original index\n",
    "\n",
    "# normalize and standardize numeric features\n",
    "def stand(sample):\n",
    "    # input: df, output: df\n",
    "    numeric = np.array(sample.loc[:, ['latitude', 'longitude',\n",
    "                                      'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation']])\n",
    "    # standarization\n",
    "    stand = (numeric - np.mean(numeric, axis=0)) / np.std(numeric, axis=0)\n",
    "    stand = pd.DataFrame(stand)\n",
    "    stand.columns = ['latitude', 'longitude', 'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation']\n",
    "    return stand  # updated index\n",
    "\n",
    "# data preprocessing\n",
    "def data_preprocessing(data):\n",
    "    # input: df, output: array\n",
    "    sample = month_season(data)\n",
    "    cate_var = onehotcode(sample)  # original index\n",
    "    cate_var.index = range(len(cate_var))  # index update\n",
    "    nume_var = stand(sample)\n",
    "    nume_var.index = range(len(nume_var))  # index update\n",
    "    final = pd.concat([nume_var, cate_var], axis=1)\n",
    "    return final\n",
    "\n",
    "def data_pre1(data):\n",
    "    # input: df, output: df\n",
    "    sample = month_season(data)\n",
    "    cate_var = onehotcode(sample)\n",
    "    cate_var.index = range(len(cate_var))\n",
    "    nume_var = sample.loc[:, ['latitude', 'longitude',\n",
    "                              'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation']]\n",
    "    nume_var.index = range(len(nume_var))\n",
    "    final = pd.concat([nume_var, cate_var], axis=1)\n",
    "    return final\n",
    "\n",
    "\n",
    "def data_pre2(data):\n",
    "    # input: data_pre1(data):df, output: df\n",
    "    dropped = data.drop(columns=['latitude', 'longitude', 'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation'])\n",
    "    dropped.index = range(len(dropped))  # index update\n",
    "\n",
    "    numeric = np.array(data.loc[:, ['latitude', 'longitude',\n",
    "                                    'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation']])\n",
    "    stand = (numeric - np.mean(numeric, axis=0)) / np.std(numeric, axis=0)\n",
    "    standf = pd.DataFrame(stand)  # index update\n",
    "    standf.columns = ['latitude', 'longitude', 'DUEXTTAU_7', 'DUEXTTAU_50', 'elevation']\n",
    "    final = pd.concat([standf, dropped], axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sampling\n",
    "def ramdomsampling(data):\n",
    "    # input: df\n",
    "    # output: np.array\n",
    "\n",
    "    # train and test split\n",
    "    trainset, testset = train_test_split(data, test_size=0.15, random_state=2020)\n",
    "\n",
    "    # original y for both train and test\n",
    "    y_train_orig = trainset[\"DUEXTTAU_7\"].values\n",
    "    y_test_orig = testset[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    # data preprocessing\n",
    "    train = data_preprocessing(trainset)\n",
    "    test = data_preprocessing(testset)\n",
    "\n",
    "    # feature and label split\n",
    "    X_train_rs, y_train_rs = train.drop(columns=[\"DUEXTTAU_7\"]).values, train[\"DUEXTTAU_7\"].values\n",
    "    X_test_rs, y_test_rs = test.drop(columns=[\"DUEXTTAU_7\"]).values, test[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    return X_train_rs, y_train_rs, X_test_rs, y_test_rs, y_train_orig, y_test_orig\n",
    "\n",
    "\n",
    "# Leave one day out\n",
    "def leaveoneday(data):\n",
    "    # input: df(original dataset)\n",
    "    # output: np.array(transfered dataset)\n",
    "    data = data_pre1(data)\n",
    "\n",
    "    # train and test split\n",
    "    trainset = data[data['Thursday'] != 1]  # Thursday\n",
    "    testset = data[data['Thursday'] == 1]\n",
    "\n",
    "    # original y for both train and test\n",
    "    y_train_orig = trainset[\"DUEXTTAU_7\"].values\n",
    "    y_test_orig = testset[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    # data preprocessing\n",
    "    train = data_pre2(trainset)\n",
    "    test = data_pre2(testset)\n",
    "\n",
    "    # feature and label split\n",
    "    X_train_loo, y_train_loo = train.drop(columns=[\"DUEXTTAU_7\"]).values, train[\"DUEXTTAU_7\"].values\n",
    "    X_test_loo, y_test_loo = test.drop(columns=[\"DUEXTTAU_7\"]).values, test[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    return X_train_loo, y_train_loo, X_test_loo, y_test_loo, y_train_orig, y_test_orig\n",
    "\n",
    "\n",
    "\n",
    "#randomly sampling\n",
    "def ramdomsampling2(data):\n",
    "    # input: df\n",
    "    # output: np.array\n",
    "\n",
    "    # train and test split\n",
    "    trainset, testset = train_test_split(data, test_size=0.15, random_state=2020)\n",
    "\n",
    "    # original y for both train and test\n",
    "    y_train_orig = trainset[\"DUEXTTAU_7\"].values\n",
    "    y_test_orig = testset[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    # data preprocessing\n",
    "    train = data_pre2(trainset)\n",
    "    test = data_pre2(testset)\n",
    "\n",
    "    # feature and label split\n",
    "    X_train_rs, y_train_rs = train.drop(columns=[\"DUEXTTAU_7\"]).values, train[\"DUEXTTAU_7\"].values\n",
    "    X_test_rs, y_test_rs = test.drop(columns=[\"DUEXTTAU_7\"]).values, test[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    return X_train_rs, y_train_rs, X_test_rs, y_test_rs, y_train_orig, y_test_orig\n",
    "\n",
    "\n",
    "# Leave one day out\n",
    "def leaveoneday2(data):\n",
    "    # input: df(original dataset)\n",
    "    # output: np.array(transfered dataset)\n",
    "    # train and test split\n",
    "    trainset = data[data['Thursday'] != 1]  # Thursday\n",
    "    testset = data[data['Thursday'] == 1]\n",
    "\n",
    "    # original y for both train and test\n",
    "    y_train_orig = trainset[\"DUEXTTAU_7\"].values\n",
    "    y_test_orig = testset[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    # data preprocessing\n",
    "    train = data_pre2(trainset)\n",
    "    test = data_pre2(testset)\n",
    "\n",
    "    # feature and label split\n",
    "    X_train_loo, y_train_loo = train.drop(columns=[\"DUEXTTAU_7\"]).values, train[\"DUEXTTAU_7\"].values\n",
    "    X_test_loo, y_test_loo = test.drop(columns=[\"DUEXTTAU_7\"]).values, test[\"DUEXTTAU_7\"].values\n",
    "\n",
    "    return X_train_loo, y_train_loo, X_test_loo, y_test_loo, y_train_orig, y_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model, X_train, y_train, X_test, y_test, y_train_orig, y_test_orig):\n",
    "    results = {}\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_train_pred = y_train_hat * np.std(y_train_orig) + np.mean(y_train_orig)\n",
    "    results['Train R2'] = r2_score(y_train_orig, y_train_pred)\n",
    "    results['Train MAE'] = sum(abs(y_train_orig - y_train_pred)) / y_train_orig.shape[0]\n",
    "    results['Train MSE'] = mean_squared_error(y_train_orig, y_train_pred)\n",
    "    results['Train RMSE'] = np.sqrt(results['Train MSE'])\n",
    "\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    y_test_pred = y_test_hat * np.std(y_test_orig) + np.mean(y_test_orig)\n",
    "    results['Test R2'] = r2_score(y_test_orig, y_test_pred)\n",
    "    results['Test MAE'] = sum(abs(y_test_orig - y_test_pred)) / y_test_orig.shape[0]\n",
    "    results['Test MSE'] = mean_squared_error(y_test_orig, y_test_pred)\n",
    "    results['Test RMSE'] = np.sqrt(results['Test MSE'])\n",
    "\n",
    "    return results, y_test_orig, y_test_pred\n",
    "\n",
    "\n",
    "def build_model(tr_x):\n",
    "    model = Sequential()\n",
    "    #first layer with sample data input\n",
    "    model.add(Dense(units=64, input_shape=(tr_x.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #second layer\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #third layer\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #forth layer\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    #fifth layer\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    "    #final layer and output the result\n",
    "    model.add(Dense(units=1))\n",
    "    #set the model loss function\n",
    "    model.compile(optimizer= 'adam', loss=\"mse\", metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_whole(X_train, y_train, X_test, y_test, y_train_orig, y_test_orig):\n",
    "    results = {}\n",
    "\n",
    "    model = build_model(X_train)\n",
    "\n",
    "    rlst = EarlyStopping(monitor='val_loss', min_delta=.0001,\n",
    "                         patience=5, verbose=True, mode='min')\n",
    "    mod = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=500, epochs=30,\n",
    "                    callbacks=[rlst], verbose=1)\n",
    "\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_train_pred = y_train_hat * np.std(y_train_orig) + np.mean(y_train_orig)\n",
    "    results['Train R2'] = r2_score(y_train_orig, y_train_pred)\n",
    "#     results['Train MAE'] = sum(abs(y_train_orig - y_train_pred)) / y_train_orig.shape[0]\n",
    "    results['Train MSE'] = mean_squared_error(y_train_orig, y_train_pred)\n",
    "    results['Train RMSE'] = np.sqrt(results['Train MSE'])\n",
    "\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    y_test_pred = y_test_hat * np.std(y_test_orig) + np.mean(y_test_orig)\n",
    "    results['Test R2'] = r2_score(y_test_orig, y_test_pred)\n",
    "#     results['Test MAE'] = sum(abs(y_test_orig - y_test_pred)) / y_test_orig.shape[0]\n",
    "    results['Test MSE'] = mean_squared_error(y_test_orig, y_test_pred)\n",
    "    results['Test RMSE'] = np.sqrt(results['Test MSE'])\n",
    "\n",
    "    return results, y_test_orig, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3W dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usedata = pd.read_csv(\"//Users//dulichen//PycharmProjects//cisi567//venv//lib//PA_copy//thesis//3w_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dulichen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling(usedata)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday(usedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "Ridge = linear_model.Ridge()\n",
    "#rf = RandomForestRegressor(n_jobs = -1, n_estimators=200, max_depth = 3, random_state = 2019)\n",
    "XGB = XGBRegressor(n_jobs = -1, learning_rate = 1, n_estimators=200, max_depth = 3, random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.33955309650374577, 'Train MAE': 0.10155931792599611, 'Train MSE': 0.022936688896570412, 'Train RMSE': 0.15144863451537097, 'Test R2': 0.34035708546167265, 'Test MAE': 0.10152188784933038, 'Test MSE': 0.02291425717957272, 'Test RMSE': 0.15137455922172893}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.3297490091082562, 'Train MAE': 0.1025982670562608, 'Train MSE': 0.023170419537013286, 'Train RMSE': 0.15221832851865535, 'Test R2': 0.3975777168901755, 'Test MAE': 0.09665569576983345, 'Test MSE': 0.021501717530546954, 'Test RMSE': 0.1466346395997445}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGB\n",
    "XGB_rs=train_predict(XGB,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"XGB_rs results: \")\n",
    "print(XGB_rs[0])\n",
    "XGB_loo=train_predict(XGB,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"XGB_loo results: \")\n",
    "print(XGB_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28075336 samples, validate on 4954472 samples\n",
      "Epoch 1/30\n",
      "28075336/28075336 [==============================] - 184s 7us/step - loss: 0.3962 - mae: 0.4199 - val_loss: 0.3539 - val_mae: 0.4186\n",
      "Epoch 2/30\n",
      "28075336/28075336 [==============================] - 181s 6us/step - loss: 0.3783 - mae: 0.4099 - val_loss: 0.3524 - val_mae: 0.4256\n",
      "Epoch 3/30\n",
      "28075336/28075336 [==============================] - 165s 6us/step - loss: 0.3755 - mae: 0.4085 - val_loss: 0.3466 - val_mae: 0.4170\n",
      "Epoch 4/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3743 - mae: 0.4078 - val_loss: 0.3460 - val_mae: 0.4186\n",
      "Epoch 5/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3734 - mae: 0.4074 - val_loss: 0.3465 - val_mae: 0.4190\n",
      "Epoch 6/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3725 - mae: 0.4070 - val_loss: 0.3503 - val_mae: 0.4173\n",
      "Epoch 7/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3721 - mae: 0.4068 - val_loss: 0.3401 - val_mae: 0.4110\n",
      "Epoch 8/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3721 - mae: 0.4068 - val_loss: 0.3392 - val_mae: 0.4114\n",
      "Epoch 9/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3717 - mae: 0.4066 - val_loss: 0.3488 - val_mae: 0.4226\n",
      "Epoch 10/30\n",
      "28075336/28075336 [==============================] - 161s 6us/step - loss: 0.3714 - mae: 0.4063 - val_loss: 0.3389 - val_mae: 0.4081\n",
      "Epoch 11/30\n",
      "28075336/28075336 [==============================] - 162s 6us/step - loss: 0.3710 - mae: 0.4060 - val_loss: 0.3352 - val_mae: 0.4082\n",
      "Epoch 12/30\n",
      "28075336/28075336 [==============================] - 162s 6us/step - loss: 0.3705 - mae: 0.4058 - val_loss: 0.3406 - val_mae: 0.4104\n",
      "Epoch 13/30\n",
      "28075336/28075336 [==============================] - 162s 6us/step - loss: 0.3704 - mae: 0.4055 - val_loss: 0.3436 - val_mae: 0.4116\n",
      "Epoch 14/30\n",
      "28075336/28075336 [==============================] - 173s 6us/step - loss: 0.3701 - mae: 0.4052 - val_loss: 0.3392 - val_mae: 0.4072\n",
      "Epoch 15/30\n",
      "28075336/28075336 [==============================] - 175s 6us/step - loss: 0.3699 - mae: 0.4051 - val_loss: 0.3377 - val_mae: 0.4085\n",
      "Epoch 16/30\n",
      "28075336/28075336 [==============================] - 174s 6us/step - loss: 0.3696 - mae: 0.4051 - val_loss: 0.3385 - val_mae: 0.3963\n",
      "Epoch 00016: early stopping\n",
      "nn_rs results: \n",
      "{'Train R2': 0.6611817906548375, 'Train MSE': 0.011766832154262849, 'Train RMSE': 0.10847503009569921, 'Test R2': 0.6615360365063779, 'Test MSE': 0.011757346489408462, 'Test RMSE': 0.10843129847700092}\n",
      "Train on 28311264 samples, validate on 4718544 samples\n",
      "Epoch 1/30\n",
      "28311264/28311264 [==============================] - 186s 7us/step - loss: 0.3864 - mae: 0.4173 - val_loss: 0.4564 - val_mae: 0.4527\n",
      "Epoch 2/30\n",
      "28311264/28311264 [==============================] - 178s 6us/step - loss: 0.3719 - mae: 0.4095 - val_loss: 0.4481 - val_mae: 0.4493\n",
      "Epoch 3/30\n",
      "28311264/28311264 [==============================] - 177s 6us/step - loss: 0.3685 - mae: 0.4072 - val_loss: 0.4439 - val_mae: 0.4402\n",
      "Epoch 4/30\n",
      "28311264/28311264 [==============================] - 177s 6us/step - loss: 0.3671 - mae: 0.4064 - val_loss: 0.4475 - val_mae: 0.4448\n",
      "Epoch 5/30\n",
      "28311264/28311264 [==============================] - 177s 6us/step - loss: 0.3662 - mae: 0.4059 - val_loss: 0.4530 - val_mae: 0.4439\n",
      "Epoch 6/30\n",
      "28311264/28311264 [==============================] - 177s 6us/step - loss: 0.3655 - mae: 0.4056 - val_loss: 0.4733 - val_mae: 0.4521\n",
      "Epoch 7/30\n",
      "28311264/28311264 [==============================] - 177s 6us/step - loss: 0.3649 - mae: 0.4053 - val_loss: 0.4819 - val_mae: 0.4691\n",
      "Epoch 8/30\n",
      "28311264/28311264 [==============================] - 176s 6us/step - loss: 0.3648 - mae: 0.4052 - val_loss: 0.4911 - val_mae: 0.4659\n",
      "Epoch 00008: early stopping\n",
      "nn_loo results: \n",
      "{'Train R2': 0.6669270647657505, 'Train MSE': 0.011514253243451759, 'Train RMSE': 0.10730448845901908, 'Test R2': 0.5089229817374781, 'Test MSE': 0.017527570988769416, 'Test RMSE': 0.13239173308318544}\n"
     ]
    }
   ],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "usedata = pd.read_csv(\"//Users//dulichen//PycharmProjects//cisi567//venv//lib//PA_copy//thesis//Combined_MERRA2+G5NR+Elevation_2005-2006.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dulichen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling(usedata)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday(usedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "Ridge = linear_model.Ridge()\n",
    "# rf = RandomForestRegressor(n_jobs = -1, n_estimators=200, max_depth = 3, random_state = 2019)\n",
    "XGB = XGBRegressor(n_jobs = -1, learning_rate = 1, n_estimators=200, max_depth = 3, random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.3353387247174612, 'Train MAE': 0.11553303335359358, 'Train MSE': 0.02849950897119243, 'Train RMSE': 0.16881797585326164, 'Test R2': 0.3355294333210507, 'Test MAE': 0.11551338515181221, 'Test MSE': 0.02848124947130029, 'Test RMSE': 0.16876388675098797}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.33277273502408966, 'Train MAE': 0.11621531697898635, 'Train MSE': 0.02898136272979015, 'Train RMSE': 0.17023913395512252, 'Test R2': 0.3521679875419622, 'Test MAE': 0.1116263993790547, 'Test MSE': 0.02558274502882191, 'Test RMSE': 0.15994606912588352}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGB\n",
    "XGB_rs=train_predict(XGB,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"XGB_rs results: \")\n",
    "print(XGB_rs[0])\n",
    "XGB_loo=train_predict(XGB,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"XGB_loo results: \")\n",
    "print(XGB_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholeyear=data_pre1(usedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143522380, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholeyear.shape #(143522380, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring=wholeyear[wholeyear['spring']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring.to_csv('spring.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36175504, 18)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spring.shape  #(36175504, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling2(spring)\n",
    "#(30749178, 17)   (5426326,)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday2(spring)\n",
    "#(31063748, 17)   (5111756,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.1962342556479587, 'Train MAE': 0.13269654675910064, 'Train MSE': 0.03265223913240167, 'Train RMSE': 0.18069930584371838, 'Test R2': 0.19638105769992764, 'Test MAE': 0.1327722268443726, 'Test MSE': 0.03269426976275191, 'Test RMSE': 0.18081556836387708}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.19116706781169945, 'Train MAE': 0.13372404190045115, 'Train MSE': 0.033078527368301816, 'Train RMSE': 0.18187503228398838, 'Test R2': 0.22662237892640735, 'Test MAE': 0.12775364944342804, 'Test MSE': 0.030152178321998423, 'Test RMSE': 0.17364382604054318}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30749178 samples, validate on 5426326 samples\n",
      "Epoch 1/30\n",
      "30749178/30749178 [==============================] - 128s 4us/step - loss: 0.6424 - mae: 0.5741 - val_loss: 0.6090 - val_mae: 0.5735\n",
      "Epoch 2/30\n",
      "30749178/30749178 [==============================] - 124s 4us/step - loss: 0.6269 - mae: 0.5664 - val_loss: 0.6010 - val_mae: 0.5656\n",
      "Epoch 3/30\n",
      "30749178/30749178 [==============================] - 123s 4us/step - loss: 0.6243 - mae: 0.5656 - val_loss: 0.5979 - val_mae: 0.5624\n",
      "Epoch 4/30\n",
      "30749178/30749178 [==============================] - 119s 4us/step - loss: 0.6235 - mae: 0.5653 - val_loss: 0.6035 - val_mae: 0.5765\n",
      "Epoch 5/30\n",
      "30749178/30749178 [==============================] - 121s 4us/step - loss: 0.6225 - mae: 0.5650 - val_loss: 0.5979 - val_mae: 0.5632\n",
      "Epoch 6/30\n",
      "30749178/30749178 [==============================] - 120s 4us/step - loss: 0.6220 - mae: 0.5648 - val_loss: 0.5959 - val_mae: 0.5636\n",
      "Epoch 7/30\n",
      "30749178/30749178 [==============================] - 120s 4us/step - loss: 0.6217 - mae: 0.5647 - val_loss: 0.5964 - val_mae: 0.5623\n",
      "Epoch 8/30\n",
      "30749178/30749178 [==============================] - 120s 4us/step - loss: 0.6211 - mae: 0.5644 - val_loss: 0.6002 - val_mae: 0.5647\n",
      "Epoch 9/30\n",
      "30749178/30749178 [==============================] - 120s 4us/step - loss: 0.6207 - mae: 0.5642 - val_loss: 0.5969 - val_mae: 0.5684\n",
      "Epoch 10/30\n",
      "30749178/30749178 [==============================] - 120s 4us/step - loss: 0.6205 - mae: 0.5641 - val_loss: 0.5940 - val_mae: 0.5600\n",
      "Epoch 11/30\n",
      "30749178/30749178 [==============================] - 121s 4us/step - loss: 0.6204 - mae: 0.5639 - val_loss: 0.5911 - val_mae: 0.5578\n",
      "Epoch 12/30\n",
      "30749178/30749178 [==============================] - 121s 4us/step - loss: 0.6201 - mae: 0.5637 - val_loss: 0.5932 - val_mae: 0.5583\n",
      "Epoch 13/30\n",
      "30749178/30749178 [==============================] - 121s 4us/step - loss: 0.6199 - mae: 0.5638 - val_loss: 0.5900 - val_mae: 0.5546\n",
      "Epoch 14/30\n",
      "30749178/30749178 [==============================] - 122s 4us/step - loss: 0.6195 - mae: 0.5636 - val_loss: 0.5951 - val_mae: 0.5599\n",
      "Epoch 15/30\n",
      "30749178/30749178 [==============================] - 127s 4us/step - loss: 0.6195 - mae: 0.5636 - val_loss: 0.5893 - val_mae: 0.5527\n",
      "Epoch 16/30\n",
      "30749178/30749178 [==============================] - 132s 4us/step - loss: 0.6192 - mae: 0.5635 - val_loss: 0.5925 - val_mae: 0.5569\n",
      "Epoch 17/30\n",
      "30749178/30749178 [==============================] - 126s 4us/step - loss: 0.6190 - mae: 0.5634 - val_loss: 0.5891 - val_mae: 0.5540\n",
      "Epoch 18/30\n",
      "30749178/30749178 [==============================] - 123s 4us/step - loss: 0.6188 - mae: 0.5633 - val_loss: 0.5893 - val_mae: 0.5533\n",
      "Epoch 19/30\n",
      "30749178/30749178 [==============================] - 124s 4us/step - loss: 0.6189 - mae: 0.5633 - val_loss: 0.5889 - val_mae: 0.5501\n",
      "Epoch 20/30\n",
      "30749178/30749178 [==============================] - 127s 4us/step - loss: 0.6186 - mae: 0.5633 - val_loss: 0.5924 - val_mae: 0.5538\n",
      "Epoch 21/30\n",
      "30749178/30749178 [==============================] - 132s 4us/step - loss: 0.6186 - mae: 0.5633 - val_loss: 0.5950 - val_mae: 0.5615\n",
      "Epoch 22/30\n",
      "30749178/30749178 [==============================] - 129s 4us/step - loss: 0.6185 - mae: 0.5632 - val_loss: 0.5900 - val_mae: 0.5530\n",
      "Epoch 23/30\n",
      "30749178/30749178 [==============================] - 127s 4us/step - loss: 0.6184 - mae: 0.5632 - val_loss: 0.5947 - val_mae: 0.5599\n",
      "Epoch 24/30\n",
      "30749178/30749178 [==============================] - 129s 4us/step - loss: 0.6183 - mae: 0.5631 - val_loss: 0.5910 - val_mae: 0.5550\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-91ea480be148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##Neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn_rs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_whole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_rs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_rs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_orig_rs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_orig_rs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nn_rs results: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_rs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnn_loo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_whole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_loo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_loo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_loo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_loo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_orig_loo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_orig_loo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-049d4f7f4e2c>\u001b[0m in \u001b[0;36mtrain_whole\u001b[0;34m(X_train, y_train, X_test, y_test, y_train_orig, y_test_orig)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train RMSE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train MSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0my_test_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_hat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Test R2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3719\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3720\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;34m\"\"\"Implementation of constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36175504, 18)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summer=wholeyear[wholeyear['summer']==1]\n",
    "summer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer.to_csv('summer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling2(summer)\n",
    "#(30749178, 17)   (5426326,)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday2(summer)\n",
    "#(31063748, 17)   (5111756,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.37225852677538585, 'Train MAE': 0.14204153939591965, 'Train MSE': 0.04429733821391231, 'Train RMSE': 0.21046932843982827, 'Test R2': 0.3715953029040734, 'Test MAE': 0.14208230465255553, 'Test MSE': 0.044340008477714195, 'Test RMSE': 0.21057067335627294}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.3741068570410616, 'Train MAE': 0.1424819947397081, 'Train MSE': 0.04490873907618291, 'Train RMSE': 0.21191682112607982, 'Test R2': 0.36285197487938103, 'Test MAE': 0.13887156621649027, 'Test MSE': 0.04033504430526068, 'Test RMSE': 0.2008358640912043}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35782292, 18)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fall=wholeyear[wholeyear['fall']==1]\n",
    "fall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall.to_csv('fall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling2(fall)\n",
    "#(30414948, 17)   (5367344,)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday2(fall)\n",
    "#(30670536, 17)   (5111756,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.34210209979405526, 'Train MAE': 0.08439381375831491, 'Train MSE': 0.013669054759758617, 'Train RMSE': 0.11691473286014306, 'Test R2': 0.3424883692031443, 'Test MAE': 0.08435937122391421, 'Test MSE': 0.013662419545146437, 'Test RMSE': 0.11688635311766056}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.343936343722699, 'Train MAE': 0.08394325487362185, 'Train MSE': 0.013549417478227558, 'Train RMSE': 0.11640196509607369, 'Test R2': 0.3307592652699465, 'Test MAE': 0.08698660270461918, 'Test MSE': 0.014383918673393357, 'Test RMSE': 0.11993297575476629}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35389080, 18)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winter=wholeyear[wholeyear['winter']==1]\n",
    "winter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter.to_csv('winter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs=ramdomsampling2(winter)\n",
    "#(30414948, 17)   (5367344,)\n",
    "X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo=leaveoneday2(winter)\n",
    "#(30670536, 17)   (5111756,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_rs results: \n",
      "{'Train R2': 0.12331290051773314, 'Train MAE': 0.08687971447350698, 'Train MSE': 0.016837267915938207, 'Train RMSE': 0.12975849843435383, 'Test R2': 0.12313020490331572, 'Test MAE': 0.08690769132680914, 'Test MSE': 0.016845264893274925, 'Test RMSE': 0.12978930962631294}\n",
      "Ridge_loo results: \n",
      "{'Train R2': 0.1175159773393355, 'Train MAE': 0.08827289846951392, 'Train MSE': 0.01749622382516927, 'Train RMSE': 0.13227329218390715, 'Test R2': 0.1631013183497959, 'Test MAE': 0.07947008884771077, 'Test MSE': 0.01296624916878019, 'Test RMSE': 0.11386943913438842}\n"
     ]
    }
   ],
   "source": [
    "##Ridge model\n",
    "Ridge_rs=train_predict(Ridge,X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"Ridge_rs results: \")\n",
    "print(Ridge_rs[0])\n",
    "Ridge_loo=train_predict(Ridge,X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"Ridge_loo results: \")\n",
    "print(Ridge_loo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network\n",
    "nn_rs=train_whole(X_train_rs, y_train_rs,X_test_rs, y_test_rs,y_train_orig_rs,y_test_orig_rs)\n",
    "print(\"nn_rs results: \")\n",
    "print(nn_rs[0])\n",
    "nn_loo=train_whole(X_train_loo, y_train_loo,X_test_loo, y_test_loo,y_train_orig_loo,y_test_orig_loo)\n",
    "print(\"nn_loo results: \")\n",
    "print(nn_loo[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
